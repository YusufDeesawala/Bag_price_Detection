{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df_extra = pd.read_csv('training_extra.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "test_df['Price'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(train_df)\n",
    "train_extra_len = len(train_df_extra)\n",
    "test_len = len(test_df)\n",
    "final_df_len = train_len + train_extra_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all files to apply the preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.concat([train_df, train_df_extra, test_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4194318, 11)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Material</th>\n",
       "      <th>Size</th>\n",
       "      <th>Compartments</th>\n",
       "      <th>Laptop Compartment</th>\n",
       "      <th>Waterproof</th>\n",
       "      <th>Style</th>\n",
       "      <th>Color</th>\n",
       "      <th>Weight Capacity (kg)</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jansport</td>\n",
       "      <td>Leather</td>\n",
       "      <td>Medium</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Tote</td>\n",
       "      <td>Black</td>\n",
       "      <td>11.611723</td>\n",
       "      <td>112.15875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jansport</td>\n",
       "      <td>Canvas</td>\n",
       "      <td>Small</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Green</td>\n",
       "      <td>27.078537</td>\n",
       "      <td>68.88056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Under Armour</td>\n",
       "      <td>Leather</td>\n",
       "      <td>Small</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Red</td>\n",
       "      <td>16.643760</td>\n",
       "      <td>39.17320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Nylon</td>\n",
       "      <td>Small</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Green</td>\n",
       "      <td>12.937220</td>\n",
       "      <td>80.60793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>Canvas</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Green</td>\n",
       "      <td>17.749338</td>\n",
       "      <td>86.02312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         Brand Material    Size  Compartments Laptop Compartment  \\\n",
       "0   0      Jansport  Leather  Medium           7.0                Yes   \n",
       "1   1      Jansport   Canvas   Small          10.0                Yes   \n",
       "2   2  Under Armour  Leather   Small           2.0                Yes   \n",
       "3   3          Nike    Nylon   Small           8.0                Yes   \n",
       "4   4        Adidas   Canvas  Medium           1.0                Yes   \n",
       "\n",
       "  Waterproof      Style  Color  Weight Capacity (kg)      Price  \n",
       "0         No       Tote  Black             11.611723  112.15875  \n",
       "1        Yes  Messenger  Green             27.078537   68.88056  \n",
       "2         No  Messenger    Red             16.643760   39.17320  \n",
       "3         No  Messenger  Green             12.937220   80.60793  \n",
       "4        Yes  Messenger  Green             17.749338   86.02312  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "Brand                   132985\n",
       "Material                116575\n",
       "Size                     92166\n",
       "Compartments                 0\n",
       "Laptop Compartment      103495\n",
       "Waterproof               99135\n",
       "Style                   109333\n",
       "Color                   140402\n",
       "Weight Capacity (kg)      1885\n",
       "Price                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value counts for all categorical cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand\n",
      "Under Armour    841174\n",
      "Adidas          837173\n",
      "Nike            802680\n",
      "Puma            793635\n",
      "Jansport        786671\n",
      "Name: count, dtype: int64\n",
      "Material\n",
      "Polyester    1113909\n",
      "Leather      1025175\n",
      "Nylon         990149\n",
      "Canvas        948510\n",
      "Name: count, dtype: int64\n",
      "Size\n",
      "Medium    1422262\n",
      "Large     1377979\n",
      "Small     1301911\n",
      "Name: count, dtype: int64\n",
      "Color\n",
      "Pink     723018\n",
      "Gray     699344\n",
      "Blue     670497\n",
      "Red      661616\n",
      "Black    651603\n",
      "Green    647838\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "categ_cols = ['Brand', 'Material', 'Size','Color']\n",
    "\n",
    "for i in range(len(categ_cols)):\n",
    "    print(df_merged[categ_cols[i]].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011562"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['Weight Capacity (kg)'].nunique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling up all NaN vals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "imputer_cols = ['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof', 'Style', 'Color']\n",
    "\n",
    "df_merged[imputer_cols] = imputer.fit_transform(df_merged[imputer_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_num = SimpleImputer(strategy = 'median')\n",
    "\n",
    "imputer_num_cols = ['Weight Capacity (kg)']\n",
    "\n",
    "df_merged[imputer_num_cols] = imputer_num.fit_transform(df_merged[imputer_num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9081/1473090586.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[yes_no_cols] = df_merged[yes_no_cols].replace({'Yes': 1, 'No': 0})\n"
     ]
    }
   ],
   "source": [
    "yes_no_cols = ['Laptop Compartment', 'Waterproof']\n",
    "\n",
    "df_merged[yes_no_cols] = df_merged[yes_no_cols].replace({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Material</th>\n",
       "      <th>Size</th>\n",
       "      <th>Compartments</th>\n",
       "      <th>Laptop Compartment</th>\n",
       "      <th>Waterproof</th>\n",
       "      <th>Style</th>\n",
       "      <th>Color</th>\n",
       "      <th>Weight Capacity (kg)</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jansport</td>\n",
       "      <td>Leather</td>\n",
       "      <td>Medium</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tote</td>\n",
       "      <td>Black</td>\n",
       "      <td>11.611723</td>\n",
       "      <td>112.15875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jansport</td>\n",
       "      <td>Canvas</td>\n",
       "      <td>Small</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Green</td>\n",
       "      <td>27.078537</td>\n",
       "      <td>68.88056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Under Armour</td>\n",
       "      <td>Leather</td>\n",
       "      <td>Small</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Red</td>\n",
       "      <td>16.643760</td>\n",
       "      <td>39.17320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Nylon</td>\n",
       "      <td>Small</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Green</td>\n",
       "      <td>12.937220</td>\n",
       "      <td>80.60793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>Canvas</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Green</td>\n",
       "      <td>17.749338</td>\n",
       "      <td>86.02312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         Brand Material    Size  Compartments  Laptop Compartment  \\\n",
       "0   0      Jansport  Leather  Medium           7.0                   1   \n",
       "1   1      Jansport   Canvas   Small          10.0                   1   \n",
       "2   2  Under Armour  Leather   Small           2.0                   1   \n",
       "3   3          Nike    Nylon   Small           8.0                   1   \n",
       "4   4        Adidas   Canvas  Medium           1.0                   1   \n",
       "\n",
       "   Waterproof      Style  Color  Weight Capacity (kg)      Price  \n",
       "0           0       Tote  Black             11.611723  112.15875  \n",
       "1           1  Messenger  Green             27.078537   68.88056  \n",
       "2           0  Messenger    Red             16.643760   39.17320  \n",
       "3           0  Messenger  Green             12.937220   80.60793  \n",
       "4           1  Messenger  Green             17.749338   86.02312  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encoding all categorical cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.preprocessing import OneHotEncoder\\n\\nonehot_cols = ['Brand', 'Material', 'Size', 'Style', 'Color']\\n\\nonehot = OneHotEncoder()\\n\\nonehot_df = pd.DataFrame(onehot.fit_transform(df_merged[onehot_cols]).toarray())\\n\\nonehot_df.columns = onehot.get_feature_names_out(onehot_cols)\\n\\ndf_merged = df_merged.drop(onehot_cols, axis=1)\\n\\ndf_merged = pd.concat([df_merged, onehot_df], axis=1)\\n\\ndf_merged.head()\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot_cols = ['Brand', 'Material', 'Size', 'Style', 'Color']\n",
    "\n",
    "onehot = OneHotEncoder()\n",
    "\n",
    "onehot_df = pd.DataFrame(onehot.fit_transform(df_merged[onehot_cols]).toarray())\n",
    "\n",
    "onehot_df.columns = onehot.get_feature_names_out(onehot_cols)\n",
    "\n",
    "df_merged = df_merged.drop(onehot_cols, axis=1)\n",
    "\n",
    "df_merged = pd.concat([df_merged, onehot_df], axis=1)\n",
    "\n",
    "df_merged.head()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset into train and test (original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df_merged[:final_df_len]\n",
    "test_df = df_merged[final_df_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"corr = final_df.corr()\\nplt.figure(figsize=(50,50))\\nsns.heatmap(corr, annot=True)\\nplt.imsave('corr.png', corr)\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''corr = final_df.corr()\n",
    "plt.figure(figsize=(50,50))\n",
    "sns.heatmap(corr, annot=True)\n",
    "plt.imsave('corr.png', corr)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'skewed_cols = final_df.skew().sort_values(ascending=False)\\nskewed_cols'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''skewed_cols = final_df.skew().sort_values(ascending=False)\n",
    "skewed_cols'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop('Price', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train test split & \n",
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model = XGBRegressor()\\n\\nmodel.fit(X_train, y_train)\\n\\ny_pred = model.predict(X_test)\\n\\nprint('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''xgboost works but lightgbm is just slightly better than xgboost'''\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "X = final_df.drop('Price', axis=1)\n",
    "y = final_df['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "'''model = XGBRegressor()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcatboost\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m catboost\u001b[38;5;241m.\u001b[39mCatBoostRegressor()\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/Workspace/ML Projects/Bag_price_Detection/.venv/lib/python3.12/site-packages/catboost/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     FeaturesData, EFstrType, EShapCalcType, EFeaturesSelectionAlgorithm, EFeaturesSelectionGrouping,\n\u001b[1;32m      3\u001b[0m     Pool, CatBoost, CatBoostClassifier, CatBoostRegressor, CatBoostRanker, CatBoostError, cv, sample_gaussian_process, train,\n\u001b[1;32m      4\u001b[0m     sum_models, _have_equal_features, to_regressor, to_classifier, to_ranker, MultiRegressionCustomMetric,\n\u001b[1;32m      5\u001b[0m     MultiRegressionCustomObjective, MultiTargetCustomMetric, MultiTargetCustomObjective\n\u001b[1;32m      6\u001b[0m )  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VERSION \u001b[38;5;28;01mas\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeaturesData\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEFstrType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEShapCalcType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEFeaturesSelectionAlgorithm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEFeaturesSelectionGrouping\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPool\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoost\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoostClassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoostRegressor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoostRanker\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatboostError\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiTargetCustomMetric\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiTargetCustomObjective\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     14\u001b[0m ]\n",
      "File \u001b[0;32m~/Workspace/ML Projects/Bag_price_Detection/.venv/lib/python3.12/site-packages/catboost/core.py:45\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot_helpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m save_plot_file, try_plot_offline, OfflineMetricVisualizer\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _catboost\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BuiltinMetric\n",
      "File \u001b[0;32m~/Workspace/ML Projects/Bag_price_Detection/.venv/lib/python3.12/site-packages/catboost/plot_helpers.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _catboost\n\u001b[1;32m      6\u001b[0m fspath \u001b[38;5;241m=\u001b[39m _catboost\u001b[38;5;241m.\u001b[39mfspath\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtry_plot_offline\u001b[39m(figs):\n",
      "File \u001b[0;32m_catboost.pyx:1\u001b[0m, in \u001b[0;36minit _catboost\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import catboost\n",
    "\n",
    "model = catboost.CatBoostRegressor()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 567\n",
      "[LightGBM] [Info] Number of data points in the train set: 3195454, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 81.361311\n",
      "RMSE: 38.87809823077521\n"
     ]
    }
   ],
   "source": [
    "'''from lightgbm import LGBMRegressor\n",
    "\n",
    "model2 = LGBMRegressor()\n",
    "\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "y_pred2 = model2.predict(X_test)\n",
    "\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred2)))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.ensemble import RandomForestRegressor\\n\\nmodel3 = RandomForestRegressor()\\n\\nmodel3.fit(X_train, y_train)\\n\\ny_pred3 = model3.predict(X_test)\\n\\nprint('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred3)))\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Random forest doesnt usually perform well for me. I have included the code so anyone can try'''\n",
    "\n",
    "'''from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model3 = RandomForestRegressor()\n",
    "\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "y_pred3 = model3.predict(X_test)\n",
    "\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred3)))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import torch\\nimport torch.nn as nn\\nimport torch.optim as optim\\nfrom torch.utils.data import DataLoader, TensorDataset\\nimport numpy as np\\nfrom tqdm import tqdm  # Import tqdm for progress bar\\n\\n# Check for GPU\\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\nprint(f\"Using device: {device}\")\\n\\n# Convert data to PyTorch tensors and move to device\\nX_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\\ny_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)\\nX_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\\ny_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1).to(device)\\n\\n# Create DataLoader\\nbatch_size = 512\\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\\n\\n# Define the Neural Network\\nclass PricePredictionNN(nn.Module):\\n    def __init__(self, input_size):\\n        super(PricePredictionNN, self).__init__()\\n        self.fc1 = nn.Linear(input_size, 64)\\n        self.relu = nn.ReLU()\\n        self.fc2 = nn.Linear(64, 32)\\n        self.fc3 = nn.Linear(32, 1)\\n    \\n    def forward(self, x):\\n        x = self.relu(self.fc1(x))\\n        x = self.relu(self.fc2(x))\\n        x = self.fc3(x)\\n        return x\\n\\n# Initialize model and move to device\\ninput_size = X_train.shape[1]\\nmodel = PricePredictionNN(input_size).to(device)\\n\\n# Loss and optimizer\\ncriterion = nn.MSELoss()\\noptimizer = optim.Adam(model.parameters(), lr=0.001)\\n\\n# Training loop with progress bar\\nepochs = 50\\n\\nfor epoch in range(epochs):\\n    epoch_loss = 0\\n    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\\n\\n    for batch_X, batch_y in progress_bar:\\n        batch_X, batch_y = batch_X.to(device), batch_y.to(device)  # Move batch to GPU\\n\\n        optimizer.zero_grad()\\n        outputs = model(batch_X)\\n        loss = criterion(outputs, batch_y)\\n        loss.backward()\\n        optimizer.step()\\n        \\n        epoch_loss += loss.item()\\n        progress_bar.set_postfix(loss=loss.item())\\n\\n    print(f\"Epoch [{epoch+1}/{epochs}] - Avg Loss: {epoch_loss/len(train_loader):.4f}\")\\n\\n# Evaluate on test set\\nmodel.eval()\\nwith torch.no_grad():\\n    y_pred = model(X_test_tensor)\\n    test_loss = criterion(y_pred, y_test_tensor)\\n    rmse = torch.sqrt(test_loss)\\n\\nprint(f\"\\nTest Loss (MSE): {test_loss.item():.4f}\")\\nprint(f\"Test RMSE: {rmse.item():.4f}\")'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''NN is the last resort with proper optimizing it can produce the best results'''\n",
    "\n",
    "'''import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Convert data to PyTorch tensors and move to device\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 512\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define the Neural Network\n",
    "class PricePredictionNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(PricePredictionNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model and move to device\n",
    "input_size = X_train.shape[1]\n",
    "model = PricePredictionNN(input_size).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop with progress bar\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "\n",
    "    for batch_X, batch_y in progress_bar:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)  # Move batch to GPU\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - Avg Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor)\n",
    "    test_loss = criterion(y_pred, y_test_tensor)\n",
    "    rmse = torch.sqrt(test_loss)\n",
    "\n",
    "print(f\"\\nTest Loss (MSE): {test_loss.item():.4f}\")\n",
    "print(f\"Test RMSE: {rmse.item():.4f}\")'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting vals and saving them in csv files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_df)\n",
    "\n",
    "submission = pd.DataFrame({'id': test_df['id'],\n",
    "                           'Price': predictions})\n",
    "submission.to_csv('submission_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"test_df_tensor = torch.tensor(test_df.values, dtype=torch.float32).to(device)\\n\\n# Make predictions\\nmodel.eval()\\nwith torch.no_grad():\\n    predictions = model(test_df_tensor).cpu().numpy()  # Move to CPU & convert to NumPy\\n\\n# Create submission DataFrame\\nsubmission = pd.DataFrame({\\n    'id': test_df['id'],\\n    'Price': predictions.flatten()  # Flatten to avoid extra dimensions\\n})\\n\\n# Save to CSV\\nsubmission.to_csv('submission_1.csv', index=False)\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''test_df_tensor = torch.tensor(test_df.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Make predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(test_df_tensor).cpu().numpy()  # Move to CPU & convert to NumPy\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Price': predictions.flatten()  # Flatten to avoid extra dimensions\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('submission_1.csv', index=False)'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
